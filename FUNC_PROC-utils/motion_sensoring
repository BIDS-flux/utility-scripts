#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import os
import pandas as pd
import numpy as np
import nibabel as nib
from bids import BIDSLayout
import glob
import subprocess

# Define base directory
# CALGARY
bids_path = '/data/debug-proc/CPIP_bids'
tedana_dir = '/data/debug-proc/CPIP_bids/derivatives/tedana/'
fmriprep_dir = '/data/debug-proc/CPIP_bids/derivatives/fmriprep2/'
subjects = "2532,3398,3136,2976,3328,2928"
ses = "1a"
bids_filters = {"task": ["laluna","partlycloudy", "rest"], "run": ["1", "2", None]}
# TORONTO
bids_path = '/data/debug-proc/CPIP_fMRI_July042025/CPIP_fMRI_July042025/'
tedana_dir = '/data/debug-proc/CPIP_fMRI_July042025/CPIP_fMRI_July042025/derivatives/tedana/'
fmriprep_dir = '/data/debug-proc/CPIP_fMRI_July042025/CPIP_fMRI_July042025/derivatives/fmriprep2/'
subjects = "3536,3675,3504,3592,3803"
ses = None
bids_filters = {"task": ["laluna","partlycloudy", "rest"], "run": ["1", "2", "3", None]}

# Define framewise displacement threshold
fd_threshold = 0.2

# Read the .bidsignore file (if it exists)
bidsignore_path = os.path.join(bids_path, ".bidsignore")
ignore_patterns = []

if os.path.exists(bidsignore_path):
    with open(bidsignore_path, "r") as f:
        ignore_patterns = [
            line.strip() for line in f if line.strip() and not line.strip().startswith("#")
        ]

expanded_ignores = []

for pattern in ignore_patterns:
    # If the pattern contains shell wildcards, resolve them
    if any(char in pattern for char in "*?[]"):
        full_pattern = os.path.join(bids_path, pattern)
        # Use recursive=True so "**" patterns are handled as well
        matches = glob.glob(full_pattern, recursive=True)

        # Keep paths relative to the BIDS root, just like the originals
        expanded_ignores.extend(
            os.path.relpath(p, bids_path) for p in matches
        )
    else:
        expanded_ignores.append(pattern)

# Remove duplicates while preserving order (Python â‰¥3.7 keeps dict order)
ignore_patterns = list(dict.fromkeys(expanded_ignores))


# Get the bids layout of the tedana dir dataset
tedana_layout = BIDSLayout(tedana_dir, validate=False, derivatives=True, ignore=ignore_patterns)
# Get the bids layout of the fmriprep dir dataset
fmriprep_layout = BIDSLayout(fmriprep_dir, validate=False, derivatives=True, ignore=ignore_patterns)

sessions = ses.split(",") if ses else [None]

for sub in subjects.split(','):
    for ses in sessions:
        nii_files = []

        for nii_f in tedana_layout.get(**bids_filters, subject=sub, session=ses, datatype='func', suffix='bold', extension='.nii.gz', space='MNI152NLin2009cAsym'):
            if "desc-denoisedREGRESSEDFltNewM_" in nii_f.filename:
                nii_files.append(nii_f)

        bids_entities = {}

        for nifti_file in nii_files:
            # Extract BIDS entities from the NIfTI file
            bids_entities['task'] = nifti_file.entities.get('task', None)
            bids_entities['run'] = nifti_file.entities.get('run', None)
            bids_entities['acquisition'] = nifti_file.entities.get('acquisition', None)

            motion_outliers_tsv = fmriprep_layout.get(**bids_entities, subject=sub, session=ses, suffix='timeseries', extension='.tsv', return_type='filename', desc='confounds')
            motion_outliers_tsv = motion_outliers_tsv[0]

            # Check if files exist before proceeding
            if not os.path.exists(nifti_file.path) or not os.path.exists(motion_outliers_tsv):
                print("##############################################")
                print(f"Files for {series_folder} not found. Skipping this acquisition.")
                continue

            # Load the NIfTI file
            nifti_img = nib.load(nifti_file.path)
            nifti_data = nifti_img.get_fdata()

            # Load motion outliers from the TSV file
            motion_outliers = pd.read_csv(motion_outliers_tsv, sep='\t')
            high_motion_indices = motion_outliers[motion_outliers['framewise_displacement'] > fd_threshold].index

            # Remove high motion volumes from the fMRI data
            nifti_data = np.delete(nifti_data, high_motion_indices, axis=-1)

            # Save the censored fMRI data as a new NIfTI file
            # Copy the original files bids entities and add censored to the description
            current_desc = nifti_file.entities.get('desc', 'denoisedREGRESSEDFltNewM')
            censored_nifti_file = nifti_file.path.replace(current_desc, f"{current_desc}censored")

            # make sure the directory is writable
            # out_dir = os.path.dirname(censored_nifti_file)
            # subprocess.run(['chmod', 'u+w', out_dir], check=True)

            nifti_img_censored = nib.Nifti1Image(nifti_data, nifti_img.affine)
            nib.save(nifti_img_censored, censored_nifti_file)

            # Print confirmation message
            print(f"Censored fMRI data for {nifti_file.filename} saved to: {censored_nifti_file}")